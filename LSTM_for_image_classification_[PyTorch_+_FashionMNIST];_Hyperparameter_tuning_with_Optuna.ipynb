{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMrOpuqNOty3s6ShTpAZWiK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorrespz/Image-Classification-Collection/blob/main/LSTM_for_image_classification_%5BPyTorch_%2B_FashionMNIST%5D%3B_Hyperparameter_tuning_with_Optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM for image classification [FashionMNIST]; Hyperparameter tuning with Optuna"
      ],
      "metadata": {
        "id": "ojlK_R5gJLzY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOHiXuhWIwKS",
        "outputId": "fdbc5e21-325e-4298-b7ac-593fd6689822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.28)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "! pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "FK4K1SqbJUKL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device =  torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "BATCHSIZE = 128\n",
        "CLASSES = 10\n",
        "DIR = os.getcwd()\n",
        "EPOCHS = 20\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 100\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 40"
      ],
      "metadata": {
        "id": "35wuihwdJjFc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device, N_TRAIN_EXAMPLES, N_VALID_EXAMPLES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skVnp7mmKyr_",
        "outputId": "4633d0e1-9825-4625-8509-f05b3d5ca529"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), 12800, 5120)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist():\n",
        "    # Load FashionMNIST dataset.\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "t7vFr6R5KSW9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define LSTM model"
      ],
      "metadata": {
        "id": "JXTqhOTBQy_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, n_inputs, n_hidden, n_rnnlayers, n_outputs, device=device):\n",
        "    super(RNN,self).__init__()\n",
        "    self.D = n_inputs\n",
        "    self.M = n_hidden\n",
        "    self.K = n_outputs\n",
        "    self.L = n_rnnlayers\n",
        "\n",
        "    self.rnn = nn.LSTM(input_size = self.D,\n",
        "                       hidden_size = self.M,\n",
        "                       num_layers = self.L,\n",
        "                       batch_first = True)\n",
        "    self.fc = nn.Linear(self.M, self.K)\n",
        "\n",
        "  def forward(self, X):\n",
        "    #initial hidden states\n",
        "    h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "    c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "\n",
        "    #get LSTM unit output:\n",
        "    out, _ = self.rnn(X, (h0,c0))\n",
        "\n",
        "    #we only want h(T) at the final time step\n",
        "    out = self.fc(out[:, -1, :])\n",
        "\n",
        "    return out\n",
        ""
      ],
      "metadata": {
        "id": "RffYRJ3GNQ-9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Rw7lhWrKRU_W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter tuning"
      ],
      "metadata": {
        "id": "GuLcCBeXQ2LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "  #trial.suggest_in(low,high,step)\n",
        "  hidden_size = trial.suggest_int('hidden_size', 64, 512, 64)\n",
        "  num_layers = trial.suggest_int('num_layers', 1,4,1)\n",
        "  model = RNN(28, hidden_size, num_layers, 10, device = device)\n",
        "  return model"
      ],
      "metadata": {
        "id": "njjrUZP7NXeb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def objective(trial):\n",
        "    # Generate the model.\n",
        "    model = define_model(trial).to(device)\n",
        "\n",
        "    # Generate the optimizers.\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "\n",
        "    # Get the FashionMNIST dataset.\n",
        "    train_loader, valid_loader = get_mnist()\n",
        "\n",
        "    # Training of the model.\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1).to(device), target.to(device)\n",
        "            # reshape the input\n",
        "            data = data.view(-1, 28, 28)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model: calculate accuracy only.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "                # Limiting validation data.\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1).to(device), target.to(device)\n",
        "                # reshape the input\n",
        "                data = data.view(-1, 28, 28)\n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "dN6l69_jLBkm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100, timeout=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2phdt3q-N_Dh",
        "outputId": "e0cc964a-9f27-46cf-c693-633aa566d1f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-26 10:32:24,784] A new study created in memory with name: no-name-ad9bc13b-b562-4254-a009-55c5e445283c\n",
            "<ipython-input-8-6cc9ff0fd1c3>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  hidden_size = trial.suggest_int('hidden_size', 64, 512, 64)\n",
            "<ipython-input-8-6cc9ff0fd1c3>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  num_layers = trial.suggest_int('num_layers', 1,4,1)\n",
            "[I 2024-03-26 10:33:14,676] Trial 0 finished with value: 0.8587890625 and parameters: {'hidden_size': 64, 'num_layers': 2, 'optimizer': 'RMSprop', 'lr': 0.00194380655705587}. Best is trial 0 with value: 0.8587890625.\n",
            "[I 2024-03-26 10:34:11,704] Trial 1 finished with value: 0.0990234375 and parameters: {'hidden_size': 256, 'num_layers': 4, 'optimizer': 'Adam', 'lr': 0.05832420275416582}. Best is trial 0 with value: 0.8587890625.\n",
            "[I 2024-03-26 10:35:17,259] Trial 2 finished with value: 0.74765625 and parameters: {'hidden_size': 512, 'num_layers': 2, 'optimizer': 'SGD', 'lr': 0.0634988357581393}. Best is trial 0 with value: 0.8587890625.\n",
            "[I 2024-03-26 10:36:45,578] Trial 3 finished with value: 0.098046875 and parameters: {'hidden_size': 448, 'num_layers': 3, 'optimizer': 'SGD', 'lr': 0.0014405754416797723}. Best is trial 0 with value: 0.8587890625.\n",
            "[I 2024-03-26 10:37:32,843] Trial 4 finished with value: 0.818359375 and parameters: {'hidden_size': 64, 'num_layers': 2, 'optimizer': 'Adam', 'lr': 0.04107046399844547}. Best is trial 0 with value: 0.8587890625.\n",
            "[I 2024-03-26 10:39:35,445] Trial 5 finished with value: 0.841015625 and parameters: {'hidden_size': 448, 'num_layers': 4, 'optimizer': 'Adam', 'lr': 0.00021218463647387022}. Best is trial 0 with value: 0.8587890625.\n",
            "[I 2024-03-26 10:40:20,420] Trial 6 finished with value: 0.8701171875 and parameters: {'hidden_size': 128, 'num_layers': 1, 'optimizer': 'RMSprop', 'lr': 0.00807174993998575}. Best is trial 6 with value: 0.8701171875.\n",
            "[I 2024-03-26 10:41:11,077] Trial 7 finished with value: 0.8765625 and parameters: {'hidden_size': 320, 'num_layers': 2, 'optimizer': 'RMSprop', 'lr': 0.0008885329462955401}. Best is trial 7 with value: 0.8765625.\n",
            "[I 2024-03-26 10:41:13,965] Trial 8 pruned. \n",
            "[I 2024-03-26 10:41:16,631] Trial 9 pruned. \n",
            "[I 2024-03-26 10:41:18,967] Trial 10 pruned. \n",
            "[I 2024-03-26 10:42:09,938] Trial 11 finished with value: 0.884375 and parameters: {'hidden_size': 192, 'num_layers': 1, 'optimizer': 'RMSprop', 'lr': 0.005658324543424291}. Best is trial 11 with value: 0.884375.\n",
            "[I 2024-03-26 10:42:12,462] Trial 12 pruned. \n",
            "[I 2024-03-26 10:42:15,433] Trial 13 pruned. \n",
            "[I 2024-03-26 10:42:17,952] Trial 14 pruned. \n",
            "[I 2024-03-26 10:42:28,285] Trial 15 pruned. \n",
            "[I 2024-03-26 10:42:31,612] Trial 16 pruned. \n",
            "[I 2024-03-26 10:42:33,939] Trial 17 pruned. \n",
            "[I 2024-03-26 10:42:36,386] Trial 18 pruned. \n",
            "[I 2024-03-26 10:42:39,441] Trial 19 pruned. \n",
            "[I 2024-03-26 10:42:41,801] Trial 20 pruned. \n",
            "[I 2024-03-26 10:43:27,143] Trial 21 finished with value: 0.8853515625 and parameters: {'hidden_size': 128, 'num_layers': 1, 'optimizer': 'RMSprop', 'lr': 0.006746303596851536}. Best is trial 21 with value: 0.8853515625.\n",
            "[I 2024-03-26 10:44:11,736] Trial 22 finished with value: 0.88125 and parameters: {'hidden_size': 128, 'num_layers': 1, 'optimizer': 'RMSprop', 'lr': 0.005223940739920878}. Best is trial 21 with value: 0.8853515625.\n",
            "[I 2024-03-26 10:44:21,003] Trial 23 pruned. \n",
            "[I 2024-03-26 10:45:06,406] Trial 24 finished with value: 0.8912109375 and parameters: {'hidden_size': 128, 'num_layers': 1, 'optimizer': 'RMSprop', 'lr': 0.004656129099041159}. Best is trial 24 with value: 0.8912109375.\n",
            "[I 2024-03-26 10:45:57,725] Trial 25 finished with value: 0.8748046875 and parameters: {'hidden_size': 192, 'num_layers': 1, 'optimizer': 'RMSprop', 'lr': 0.0048404642078467746}. Best is trial 24 with value: 0.8912109375.\n",
            "[I 2024-03-26 10:46:00,646] Trial 26 pruned. \n",
            "[I 2024-03-26 10:46:04,015] Trial 27 pruned. \n",
            "[I 2024-03-26 10:46:15,672] Trial 28 pruned. \n",
            "[I 2024-03-26 10:46:17,856] Trial 29 pruned. \n",
            "[I 2024-03-26 10:46:25,602] Trial 30 pruned. \n",
            "[I 2024-03-26 10:47:13,130] Trial 31 finished with value: 0.8796875 and parameters: {'hidden_size': 128, 'num_layers': 1, 'optimizer': 'RMSprop', 'lr': 0.004680577786452309}. Best is trial 24 with value: 0.8912109375.\n",
            "[I 2024-03-26 10:47:15,790] Trial 32 pruned. \n",
            "[I 2024-03-26 10:48:02,865] Trial 33 finished with value: 0.8779296875 and parameters: {'hidden_size': 128, 'num_layers': 1, 'optimizer': 'RMSprop', 'lr': 0.0046808105739176075}. Best is trial 24 with value: 0.8912109375.\n",
            "[I 2024-03-26 10:48:05,757] Trial 34 pruned. \n",
            "[I 2024-03-26 10:48:08,015] Trial 35 pruned. \n",
            "[I 2024-03-26 10:48:11,679] Trial 36 pruned. \n",
            "[I 2024-03-26 10:48:16,516] Trial 37 pruned. \n",
            "[I 2024-03-26 10:48:21,482] Trial 38 pruned. \n",
            "[I 2024-03-26 10:49:12,336] Trial 39 pruned. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])"
      ],
      "metadata": {
        "id": "iwu-ThWCTtkj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_trials[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCLb6fRcZmvA",
        "outputId": "f0f00b41-b36a-43e6-f1a0-fba50509c48c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenTrial(number=8, state=TrialState.PRUNED, values=[0.0998046875], datetime_start=datetime.datetime(2024, 3, 26, 10, 41, 11, 78740), datetime_complete=datetime.datetime(2024, 3, 26, 10, 41, 13, 965448), params={'hidden_size': 320, 'num_layers': 3, 'optimizer': 'RMSprop', 'lr': 0.013027321954073048}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.0998046875}, distributions={'hidden_size': IntDistribution(high=512, log=False, low=64, step=64), 'num_layers': IntDistribution(high=4, log=False, low=1, step=1), 'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop', 'SGD')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None)}, trial_id=8, value=None)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_trials[24]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19TlLFFiZ2ox",
        "outputId": "0f85b062-8fdb-49eb-aa3e-83ff10c4014f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenTrial(number=39, state=TrialState.PRUNED, values=[0.8708984375], datetime_start=datetime.datetime(2024, 3, 26, 10, 48, 21, 484066), datetime_complete=datetime.datetime(2024, 3, 26, 10, 49, 12, 336131), params={'hidden_size': 256, 'num_layers': 1, 'optimizer': 'Adam', 'lr': 0.0187436067907857}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.7271484375, 1: 0.7849609375, 2: 0.8099609375, 3: 0.8265625, 4: 0.850390625, 5: 0.8521484375, 6: 0.8482421875, 7: 0.8525390625, 8: 0.8525390625, 9: 0.85, 10: 0.851953125, 11: 0.8626953125, 12: 0.8658203125, 13: 0.859375, 14: 0.8609375, 15: 0.873828125, 16: 0.8716796875, 17: 0.86796875, 18: 0.8654296875, 19: 0.8708984375}, distributions={'hidden_size': IntDistribution(high=512, log=False, low=64, step=64), 'num_layers': IntDistribution(high=4, log=False, low=1, step=1), 'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop', 'SGD')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None)}, trial_id=39, value=None)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKb6rLFNTqGp",
        "outputId": "6fb3bb20-4aba-41b9-d2ce-d05505c163d6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  40\n",
            "  Number of pruned trials:  25\n",
            "  Number of complete trials:  15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WymYTR9dPqgP",
        "outputId": "e9aaca96-8be8-4dfc-e18f-81d919c3a5d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "  Value:  0.8912109375\n",
            "  Params: \n",
            "    hidden_size: 128\n",
            "    num_layers: 1\n",
            "    optimizer: RMSprop\n",
            "    lr: 0.004656129099041159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyQsKWwyT63s"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}