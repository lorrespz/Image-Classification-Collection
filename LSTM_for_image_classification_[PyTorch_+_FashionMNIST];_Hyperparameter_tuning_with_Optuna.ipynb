{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNFViHqWQO9oCUV/A1BqE4S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorrespz/Image-Classification-Collection/blob/main/LSTM_for_image_classification_%5BPyTorch_%2B_FashionMNIST%5D%3B_Hyperparameter_tuning_with_Optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM for image classification [FashionMNIST]; Hyperparameter tuning with Optuna"
      ],
      "metadata": {
        "id": "ojlK_R5gJLzY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOHiXuhWIwKS",
        "outputId": "68fd038a-5a28-4a0a-f380-3a7f231aa669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.28)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "! pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "FK4K1SqbJUKL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device =  torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "BATCHSIZE = 128\n",
        "CLASSES = 10\n",
        "DIR = os.getcwd()\n",
        "EPOCHS = 20\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 100\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 40"
      ],
      "metadata": {
        "id": "35wuihwdJjFc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device, N_TRAIN_EXAMPLES, N_VALID_EXAMPLES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skVnp7mmKyr_",
        "outputId": "1cecd186-1a17-4273-90eb-4046d7328471"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), 12800, 5120)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist():\n",
        "    # Load FashionMNIST dataset.\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "t7vFr6R5KSW9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define LSTM model"
      ],
      "metadata": {
        "id": "JXTqhOTBQy_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, n_inputs, n_hidden, n_rnnlayers, n_outputs, device=device):\n",
        "    super(RNN,self).__init__()\n",
        "    self.D = n_inputs\n",
        "    self.M = n_hidden\n",
        "    self.K = n_outputs\n",
        "    self.L = n_rnnlayers\n",
        "\n",
        "    self.rnn = nn.LSTM(input_size = self.D,\n",
        "                       hidden_size = self.M,\n",
        "                       num_layers = self.L,\n",
        "                       batch_first = True)\n",
        "    self.fc = nn.Linear(self.M, self.K)\n",
        "\n",
        "  def forward(self, X):\n",
        "    #initial hidden states\n",
        "    h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "    c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "\n",
        "    #get LSTM unit output:\n",
        "    out, _ = self.rnn(X, (h0,c0))\n",
        "\n",
        "    #we only want h(T) at the final time step\n",
        "    out = self.fc(out[:, -1, :])\n",
        "\n",
        "    return out\n",
        ""
      ],
      "metadata": {
        "id": "RffYRJ3GNQ-9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Rw7lhWrKRU_W"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter tuning"
      ],
      "metadata": {
        "id": "GuLcCBeXQ2LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "  #trial.suggest_in(low,high,step)\n",
        "  hidden_size = trial.suggest_int('hidden_size', 64, 512, 64)\n",
        "  num_layers = trial.suggest_int('num_layers', 1,4,1)\n",
        "  model = RNN(28, hidden_size, num_layers, 10, device = device)\n",
        "  return model"
      ],
      "metadata": {
        "id": "njjrUZP7NXeb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def objective(trial):\n",
        "    # Generate the model.\n",
        "    model = define_model(trial).to(device)\n",
        "\n",
        "    # Generate the optimizers.\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "\n",
        "    # Get the FashionMNIST dataset.\n",
        "    train_loader, valid_loader = get_mnist()\n",
        "\n",
        "    # Training of the model.\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1).to(device), target.to(device)\n",
        "            # reshape the input\n",
        "            data = data.view(-1, 28, 28)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model: calculate accuracy only.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "                # Limiting validation data.\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1).to(device), target.to(device)\n",
        "                # reshape the input\n",
        "                data = data.view(-1, 28, 28)\n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "dN6l69_jLBkm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100, timeout=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2phdt3q-N_Dh",
        "outputId": "4e7bde3d-e81b-404b-a647-137bf6da2bcb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-26 10:20:10,589] A new study created in memory with name: no-name-09dc4aff-7d97-4b79-8acd-a8296f864794\n",
            "<ipython-input-19-6cc9ff0fd1c3>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  hidden_size = trial.suggest_int('hidden_size', 64, 512, 64)\n",
            "<ipython-input-19-6cc9ff0fd1c3>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  num_layers = trial.suggest_int('num_layers', 1,4,1)\n",
            "[I 2024-03-26 10:21:02,059] Trial 0 finished with value: 0.8134765625 and parameters: {'hidden_size': 128, 'num_layers': 2, 'optimizer': 'RMSprop', 'lr': 0.00014002701573764793}. Best is trial 0 with value: 0.8134765625.\n",
            "[I 2024-03-26 10:21:48,208] Trial 1 finished with value: 0.8673828125 and parameters: {'hidden_size': 64, 'num_layers': 3, 'optimizer': 'Adam', 'lr': 0.003866242154621063}. Best is trial 1 with value: 0.8673828125.\n",
            "[I 2024-03-26 10:23:27,048] Trial 2 finished with value: 0.246875 and parameters: {'hidden_size': 512, 'num_layers': 3, 'optimizer': 'Adam', 'lr': 0.07686835479641078}. Best is trial 1 with value: 0.8673828125.\n",
            "[I 2024-03-26 10:24:34,525] Trial 3 finished with value: 0.850390625 and parameters: {'hidden_size': 512, 'num_layers': 2, 'optimizer': 'Adam', 'lr': 0.0002545662810844449}. Best is trial 1 with value: 0.8673828125.\n",
            "[I 2024-03-26 10:25:25,813] Trial 4 finished with value: 0.8689453125 and parameters: {'hidden_size': 384, 'num_layers': 2, 'optimizer': 'RMSprop', 'lr': 0.002099678119246785}. Best is trial 4 with value: 0.8689453125.\n",
            "[I 2024-03-26 10:25:30,499] Trial 5 pruned. \n",
            "[I 2024-03-26 10:25:35,166] Trial 6 pruned. \n",
            "[I 2024-03-26 10:25:37,656] Trial 7 pruned. \n",
            "[I 2024-03-26 10:25:40,681] Trial 8 pruned. \n",
            "[I 2024-03-26 10:25:42,870] Trial 9 pruned. \n",
            "[I 2024-03-26 10:25:45,151] Trial 10 pruned. \n",
            "[I 2024-03-26 10:25:47,973] Trial 11 pruned. \n",
            "[I 2024-03-26 10:26:32,958] Trial 12 finished with value: 0.8705078125 and parameters: {'hidden_size': 64, 'num_layers': 2, 'optimizer': 'Adam', 'lr': 0.005812061112432449}. Best is trial 12 with value: 0.8705078125.\n",
            "[I 2024-03-26 10:26:35,245] Trial 13 pruned. \n",
            "[I 2024-03-26 10:27:26,131] Trial 14 finished with value: 0.865625 and parameters: {'hidden_size': 256, 'num_layers': 2, 'optimizer': 'Adam', 'lr': 0.013168416383348988}. Best is trial 12 with value: 0.8705078125.\n",
            "[I 2024-03-26 10:27:39,517] Trial 15 pruned. \n",
            "[I 2024-03-26 10:27:41,787] Trial 16 pruned. \n",
            "[I 2024-03-26 10:27:44,745] Trial 17 pruned. \n",
            "[I 2024-03-26 10:27:54,325] Trial 18 pruned. \n",
            "[I 2024-03-26 10:27:56,659] Trial 19 pruned. \n",
            "[I 2024-03-26 10:28:00,036] Trial 20 pruned. \n",
            "[I 2024-03-26 10:28:04,995] Trial 21 pruned. \n",
            "[I 2024-03-26 10:28:07,239] Trial 22 pruned. \n",
            "[I 2024-03-26 10:28:54,920] Trial 23 finished with value: 0.8712890625 and parameters: {'hidden_size': 128, 'num_layers': 3, 'optimizer': 'Adam', 'lr': 0.004893335193328309}. Best is trial 23 with value: 0.8712890625.\n",
            "[I 2024-03-26 10:29:42,776] Trial 24 finished with value: 0.87734375 and parameters: {'hidden_size': 128, 'num_layers': 2, 'optimizer': 'Adam', 'lr': 0.01190032506870519}. Best is trial 24 with value: 0.87734375.\n",
            "[I 2024-03-26 10:29:55,151] Trial 25 pruned. \n",
            "[I 2024-03-26 10:29:57,434] Trial 26 pruned. \n",
            "[I 2024-03-26 10:30:02,239] Trial 27 pruned. \n",
            "[I 2024-03-26 10:30:04,614] Trial 28 pruned. \n",
            "[I 2024-03-26 10:30:07,160] Trial 29 pruned. \n",
            "[I 2024-03-26 10:30:09,673] Trial 30 pruned. \n",
            "[I 2024-03-26 10:30:12,993] Trial 31 pruned. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])"
      ],
      "metadata": {
        "id": "iwu-ThWCTtkj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKb6rLFNTqGp",
        "outputId": "b19ac774-cd6a-4751-faeb-9889f93af50c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  32\n",
            "  Number of pruned trials:  23\n",
            "  Number of complete trials:  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WymYTR9dPqgP",
        "outputId": "6257ca2e-e303-44e4-b363-ddcf595694e7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "  Value:  0.87734375\n",
            "  Params: \n",
            "    hidden_size: 128\n",
            "    num_layers: 2\n",
            "    optimizer: Adam\n",
            "    lr: 0.01190032506870519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyQsKWwyT63s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}