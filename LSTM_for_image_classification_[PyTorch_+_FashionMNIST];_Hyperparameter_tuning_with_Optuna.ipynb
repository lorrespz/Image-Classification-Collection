{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSSFfOx8N3yAIP937JYYAM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorrespz/Image-Classification-Collection/blob/main/LSTM_for_image_classification_%5BPyTorch_%2B_FashionMNIST%5D%3B_Hyperparameter_tuning_with_Optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM for image classification [FashionMNIST]; Hyperparameter tuning with Optuna"
      ],
      "metadata": {
        "id": "ojlK_R5gJLzY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOHiXuhWIwKS",
        "outputId": "1517880a-3a42-488a-c47e-7b87735ba8bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.28)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "! pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "FK4K1SqbJUKL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device =  torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "BATCHSIZE = 128\n",
        "CLASSES = 10\n",
        "DIR = os.getcwd()\n",
        "EPOCHS = 20\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 100\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 40"
      ],
      "metadata": {
        "id": "35wuihwdJjFc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device, N_TRAIN_EXAMPLES, N_VALID_EXAMPLES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skVnp7mmKyr_",
        "outputId": "43fdc6c8-b59a-430c-d67f-5569902b0c24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), 12800, 5120)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist():\n",
        "    # Load FashionMNIST dataset.\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "t7vFr6R5KSW9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define LSTM model"
      ],
      "metadata": {
        "id": "JXTqhOTBQy_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, n_inputs, n_hidden, n_rnnlayers, n_outputs, device=device):\n",
        "    super(RNN,self).__init__()\n",
        "    self.D = n_inputs\n",
        "    self.M = n_hidden\n",
        "    self.K = n_outputs\n",
        "    self.L = n_rnnlayers\n",
        "\n",
        "    self.rnn = nn.LSTM(input_size = self.D,\n",
        "                       hidden_size = self.M,\n",
        "                       num_layers = self.L,\n",
        "                       batch_first = True)\n",
        "    self.fc = nn.Linear(self.M, self.K)\n",
        "\n",
        "  def forward(self, X):\n",
        "    #initial hidden states\n",
        "    h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "    c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "\n",
        "    #get LSTM unit output:\n",
        "    out, _ = self.rnn(X, (h0,c0))\n",
        "\n",
        "    #we only want h(T) at the final time step\n",
        "    out = self.fc(out[:, -1, :])\n",
        "\n",
        "    return out\n",
        ""
      ],
      "metadata": {
        "id": "RffYRJ3GNQ-9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter tuning"
      ],
      "metadata": {
        "id": "GuLcCBeXQ2LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "  #trial.suggest_in(low,high,step)\n",
        "  hidden_size = trial.suggest_int('hidden_size', 64, 512, 64)\n",
        "  num_layers = trial.suggest_int('num_layers', 1,4,1)\n",
        "  model = RNN(28, hidden_size, num_layers, 10, device = device)\n",
        "  return model"
      ],
      "metadata": {
        "id": "njjrUZP7NXeb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def objective(trial):\n",
        "    # Generate the model.\n",
        "    model = define_model(trial).to(device)\n",
        "\n",
        "    # Generate the optimizers.\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "\n",
        "    # Get the FashionMNIST dataset.\n",
        "    train_loader, valid_loader = get_mnist()\n",
        "\n",
        "    # Training of the model.\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1).to(device), target.to(device)\n",
        "            # reshape the input\n",
        "            data = data.view(-1, 28, 28)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "                # Limiting validation data.\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1).to(device), target.to(device)\n",
        "                # reshape the input\n",
        "                data = data.view(-1, 28, 28)\n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "dN6l69_jLBkm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100, timeout=600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2phdt3q-N_Dh",
        "outputId": "7b91455e-f0a3-4f3e-c224-6aa6f109c837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-26 10:11:53,925] A new study created in memory with name: no-name-cecfc637-bd03-439f-a618-f9cb83b8499a\n",
            "<ipython-input-7-6cc9ff0fd1c3>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  hidden_size = trial.suggest_int('hidden_size', 64, 512, 64)\n",
            "<ipython-input-7-6cc9ff0fd1c3>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  num_layers = trial.suggest_int('num_layers', 1,4,1)\n",
            "[I 2024-03-26 10:12:47,708] Trial 0 finished with value: 0.0994140625 and parameters: {'hidden_size': 256, 'num_layers': 3, 'optimizer': 'Adam', 'lr': 3.644398701832356e-05}. Best is trial 0 with value: 0.0994140625.\n",
            "[I 2024-03-26 10:13:46,221] Trial 1 finished with value: 0.101171875 and parameters: {'hidden_size': 448, 'num_layers': 2, 'optimizer': 'RMSprop', 'lr': 0.0007578415419437125}. Best is trial 1 with value: 0.101171875.\n",
            "[I 2024-03-26 10:14:32,365] Trial 2 finished with value: 0.0990234375 and parameters: {'hidden_size': 128, 'num_layers': 3, 'optimizer': 'SGD', 'lr': 0.00019752572319019018}. Best is trial 1 with value: 0.101171875.\n",
            "[I 2024-03-26 10:15:20,037] Trial 3 finished with value: 0.1021484375 and parameters: {'hidden_size': 512, 'num_layers': 1, 'optimizer': 'Adam', 'lr': 0.00036899574739261736}. Best is trial 3 with value: 0.1021484375.\n",
            "[I 2024-03-26 10:16:18,606] Trial 4 finished with value: 0.0982421875 and parameters: {'hidden_size': 448, 'num_layers': 2, 'optimizer': 'Adam', 'lr': 5.7252111771967854e-05}. Best is trial 3 with value: 0.1021484375.\n",
            "[I 2024-03-26 10:16:21,077] Trial 5 pruned. \n",
            "[I 2024-03-26 10:16:23,194] Trial 6 pruned. \n",
            "[I 2024-03-26 10:16:27,805] Trial 7 pruned. \n",
            "[I 2024-03-26 10:16:30,744] Trial 8 pruned. \n",
            "[I 2024-03-26 10:17:22,975] Trial 9 finished with value: 0.190625 and parameters: {'hidden_size': 256, 'num_layers': 2, 'optimizer': 'Adam', 'lr': 1.8419858929318205e-05}. Best is trial 9 with value: 0.190625.\n",
            "[I 2024-03-26 10:17:25,742] Trial 10 pruned. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WymYTR9dPqgP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}