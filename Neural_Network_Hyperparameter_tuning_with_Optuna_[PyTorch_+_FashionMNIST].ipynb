{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8QcKlJNR54KtyU40t+Z09",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorrespz/Image-Classification-Collection/blob/main/Neural_Network_Hyperparameter_tuning_with_Optuna_%5BPyTorch_%2B_FashionMNIST%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter tuning with Optuna [PyTorch + FashionMNIST]\n",
        "\n",
        "https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_simple.py\n",
        "\n",
        "\n",
        "In this example, we optimize the validation accuracy of fashion product recognition using\n",
        "PyTorch and FashionMNIST. We optimize the neural network architecture as well as the optimizer\n",
        "configuration. As it is too time consuming to use the whole FashionMNIST dataset,\n",
        "we here use a small subset of it"
      ],
      "metadata": {
        "id": "huxs9X4qi6Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msofSVSojMe7",
        "outputId": "61756c9f-6f4f-4d5e-d9d6-f520153d8082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.0-py3-none-any.whl (379 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.28)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.2 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "No3H50j_i_iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cpu\")\n",
        "BATCHSIZE = 128\n",
        "CLASSES = 10\n",
        "DIR = os.getcwd()\n",
        "EPOCHS = 10\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 10"
      ],
      "metadata": {
        "id": "JONccuKjjDdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
        "    layers = []\n",
        "\n",
        "    in_features = 28 * 28\n",
        "    for i in range(n_layers):\n",
        "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
        "        layers.append(nn.Linear(in_features, out_features))\n",
        "        layers.append(nn.ReLU())\n",
        "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
        "        layers.append(nn.Dropout(p))\n",
        "\n",
        "        in_features = out_features\n",
        "    layers.append(nn.Linear(in_features, CLASSES))\n",
        "    layers.append(nn.LogSoftmax(dim=1))\n",
        "\n",
        "    return nn.Sequential(*layers)\n"
      ],
      "metadata": {
        "id": "WyrG4tVzj0QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist():\n",
        "    # Load FashionMNIST dataset.\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "u2UwnxCdj9-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # Generate the model.\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "\n",
        "    # Generate the optimizers.\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "\n",
        "    # Get the FashionMNIST dataset.\n",
        "    train_loader, valid_loader = get_mnist()\n",
        "\n",
        "    # Training of the model.\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "                # Limiting validation data.\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "S8nnzuMdkBcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100, timeout=600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X8T5xgCkSre",
        "outputId": "6d3c0bbf-f4b5-4763-aafa-47055fb787f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-26 07:02:37,187] A new study created in memory with name: no-name-8663a585-74e9-449f-a65a-3f0a84e13271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /content/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 19886549.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/train-images-idx3-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /content/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 328625.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /content/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6223184.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /content/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5117866.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-26 07:02:49,628] Trial 0 finished with value: 0.8015625 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_l0': 0.4247104427818627, 'optimizer': 'RMSprop', 'lr': 0.0008929501396416445}. Best is trial 0 with value: 0.8015625.\n",
            "[I 2024-03-26 07:02:57,539] Trial 1 finished with value: 0.50625 and parameters: {'n_layers': 2, 'n_units_l0': 91, 'dropout_l0': 0.2639825308698437, 'n_units_l1': 117, 'dropout_l1': 0.4592594902392836, 'optimizer': 'RMSprop', 'lr': 1.951978738505149e-05}. Best is trial 0 with value: 0.8015625.\n",
            "[I 2024-03-26 07:03:05,152] Trial 2 finished with value: 0.1015625 and parameters: {'n_layers': 2, 'n_units_l0': 97, 'dropout_l0': 0.3013736972492556, 'n_units_l1': 37, 'dropout_l1': 0.2815059285593978, 'optimizer': 'Adam', 'lr': 0.0639174795443383}. Best is trial 0 with value: 0.8015625.\n",
            "[I 2024-03-26 07:03:14,149] Trial 3 finished with value: 0.10625 and parameters: {'n_layers': 3, 'n_units_l0': 96, 'dropout_l0': 0.33701771644653933, 'n_units_l1': 127, 'dropout_l1': 0.3287092769886282, 'n_units_l2': 4, 'dropout_l2': 0.3718276615869105, 'optimizer': 'SGD', 'lr': 0.003974358986517572}. Best is trial 0 with value: 0.8015625.\n",
            "[I 2024-03-26 07:03:22,440] Trial 4 finished with value: 0.67265625 and parameters: {'n_layers': 1, 'n_units_l0': 85, 'dropout_l0': 0.34092976742648784, 'optimizer': 'Adam', 'lr': 6.661864838158039e-05}. Best is trial 0 with value: 0.8015625.\n",
            "[I 2024-03-26 07:03:23,243] Trial 5 pruned. \n",
            "[I 2024-03-26 07:03:31,777] Trial 6 finished with value: 0.63828125 and parameters: {'n_layers': 1, 'n_units_l0': 70, 'dropout_l0': 0.303093761265332, 'optimizer': 'RMSprop', 'lr': 0.061834651067249835}. Best is trial 0 with value: 0.8015625.\n",
            "[I 2024-03-26 07:03:39,595] Trial 7 finished with value: 0.6625 and parameters: {'n_layers': 1, 'n_units_l0': 98, 'dropout_l0': 0.24409896406612533, 'optimizer': 'RMSprop', 'lr': 0.03924005989389346}. Best is trial 0 with value: 0.8015625.\n",
            "[I 2024-03-26 07:03:47,616] Trial 8 finished with value: 0.6671875 and parameters: {'n_layers': 3, 'n_units_l0': 103, 'dropout_l0': 0.4259654047971607, 'n_units_l1': 52, 'dropout_l1': 0.4047869145113744, 'n_units_l2': 73, 'dropout_l2': 0.4609532614040441, 'optimizer': 'Adam', 'lr': 0.029465306651622995}. Best is trial 0 with value: 0.8015625.\n",
            "[I 2024-03-26 07:03:48,378] Trial 9 pruned. \n",
            "[I 2024-03-26 07:03:55,474] Trial 10 finished with value: 0.8203125 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.4771026106843934, 'optimizer': 'RMSprop', 'lr': 0.003100191225845699}. Best is trial 10 with value: 0.8203125.\n",
            "[I 2024-03-26 07:04:03,471] Trial 11 finished with value: 0.82734375 and parameters: {'n_layers': 1, 'n_units_l0': 127, 'dropout_l0': 0.4802107897711354, 'optimizer': 'RMSprop', 'lr': 0.003846053474329682}. Best is trial 11 with value: 0.82734375.\n",
            "[I 2024-03-26 07:04:04,315] Trial 12 pruned. \n",
            "[I 2024-03-26 07:04:12,069] Trial 13 finished with value: 0.78046875 and parameters: {'n_layers': 1, 'n_units_l0': 40, 'dropout_l0': 0.49706558353201724, 'optimizer': 'RMSprop', 'lr': 0.006736875797712441}. Best is trial 11 with value: 0.82734375.\n",
            "[I 2024-03-26 07:04:19,260] Trial 14 finished with value: 0.7484375 and parameters: {'n_layers': 1, 'n_units_l0': 127, 'dropout_l0': 0.4522735666760419, 'optimizer': 'RMSprop', 'lr': 0.00018161545037527924}. Best is trial 11 with value: 0.82734375.\n",
            "[I 2024-03-26 07:04:20,068] Trial 15 pruned. \n",
            "[I 2024-03-26 07:04:21,130] Trial 16 pruned. \n",
            "[I 2024-03-26 07:04:22,391] Trial 17 pruned. \n",
            "[I 2024-03-26 07:04:29,280] Trial 18 finished with value: 0.74453125 and parameters: {'n_layers': 1, 'n_units_l0': 46, 'dropout_l0': 0.42542652035458944, 'optimizer': 'RMSprop', 'lr': 0.00026301817741277393}. Best is trial 11 with value: 0.82734375.\n",
            "[I 2024-03-26 07:04:30,092] Trial 19 pruned. \n",
            "[I 2024-03-26 07:04:30,869] Trial 20 pruned. \n",
            "[I 2024-03-26 07:04:38,592] Trial 21 finished with value: 0.8296875 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_l0': 0.431752818211444, 'optimizer': 'RMSprop', 'lr': 0.0009596479236385157}. Best is trial 21 with value: 0.8296875.\n",
            "[I 2024-03-26 07:04:47,484] Trial 22 finished with value: 0.7734375 and parameters: {'n_layers': 1, 'n_units_l0': 117, 'dropout_l0': 0.46810407996195386, 'optimizer': 'RMSprop', 'lr': 0.0060313140609386945}. Best is trial 21 with value: 0.8296875.\n",
            "[I 2024-03-26 07:04:55,056] Trial 23 finished with value: 0.8015625 and parameters: {'n_layers': 1, 'n_units_l0': 85, 'dropout_l0': 0.44232903630015885, 'optimizer': 'RMSprop', 'lr': 0.0012902311421980703}. Best is trial 21 with value: 0.8296875.\n",
            "[I 2024-03-26 07:05:03,888] Trial 24 finished with value: 0.8078125 and parameters: {'n_layers': 1, 'n_units_l0': 118, 'dropout_l0': 0.4840213651834075, 'optimizer': 'RMSprop', 'lr': 0.00025938772817663393}. Best is trial 21 with value: 0.8296875.\n",
            "[I 2024-03-26 07:05:04,707] Trial 25 pruned. \n",
            "[I 2024-03-26 07:05:05,582] Trial 26 pruned. \n",
            "[I 2024-03-26 07:05:13,600] Trial 27 finished with value: 0.7890625 and parameters: {'n_layers': 1, 'n_units_l0': 103, 'dropout_l0': 0.485784653210282, 'optimizer': 'RMSprop', 'lr': 0.0024508197528626957}. Best is trial 21 with value: 0.8296875.\n",
            "[I 2024-03-26 07:05:14,386] Trial 28 pruned. \n",
            "[I 2024-03-26 07:05:15,160] Trial 29 pruned. \n",
            "[I 2024-03-26 07:05:15,988] Trial 30 pruned. \n",
            "[I 2024-03-26 07:05:16,818] Trial 31 pruned. \n",
            "[I 2024-03-26 07:05:17,602] Trial 32 pruned. \n",
            "[I 2024-03-26 07:05:18,406] Trial 33 pruned. \n",
            "[I 2024-03-26 07:05:19,196] Trial 34 pruned. \n",
            "[I 2024-03-26 07:05:28,322] Trial 35 finished with value: 0.81484375 and parameters: {'n_layers': 1, 'n_units_l0': 127, 'dropout_l0': 0.45549529115512855, 'optimizer': 'RMSprop', 'lr': 0.00041600561657363254}. Best is trial 21 with value: 0.8296875.\n",
            "[I 2024-03-26 07:05:29,943] Trial 36 pruned. \n",
            "[I 2024-03-26 07:05:39,197] Trial 37 finished with value: 0.7890625 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.36218361286722106, 'optimizer': 'RMSprop', 'lr': 0.0004242053124990296}. Best is trial 21 with value: 0.8296875.\n",
            "[I 2024-03-26 07:05:40,091] Trial 38 pruned. \n",
            "[I 2024-03-26 07:05:40,967] Trial 39 pruned. \n",
            "[I 2024-03-26 07:05:41,913] Trial 40 pruned. \n",
            "[I 2024-03-26 07:05:42,728] Trial 41 pruned. \n",
            "[I 2024-03-26 07:05:43,597] Trial 42 pruned. \n",
            "[I 2024-03-26 07:05:51,595] Trial 43 finished with value: 0.80703125 and parameters: {'n_layers': 1, 'n_units_l0': 108, 'dropout_l0': 0.43633706606886036, 'optimizer': 'RMSprop', 'lr': 0.0008988645940996949}. Best is trial 21 with value: 0.8296875.\n",
            "[I 2024-03-26 07:05:52,417] Trial 44 pruned. \n",
            "[I 2024-03-26 07:05:53,249] Trial 45 pruned. \n",
            "[I 2024-03-26 07:05:54,469] Trial 46 pruned. \n",
            "[I 2024-03-26 07:05:55,544] Trial 47 pruned. \n",
            "[I 2024-03-26 07:05:56,364] Trial 48 pruned. \n",
            "[I 2024-03-26 07:05:57,188] Trial 49 pruned. \n",
            "[I 2024-03-26 07:05:57,977] Trial 50 pruned. \n",
            "[I 2024-03-26 07:06:05,756] Trial 51 finished with value: 0.81015625 and parameters: {'n_layers': 1, 'n_units_l0': 109, 'dropout_l0': 0.4320083847203065, 'optimizer': 'RMSprop', 'lr': 0.0008062426507359337}. Best is trial 21 with value: 0.8296875.\n",
            "[I 2024-03-26 07:06:13,551] Trial 52 finished with value: 0.82734375 and parameters: {'n_layers': 1, 'n_units_l0': 123, 'dropout_l0': 0.4907951030744782, 'optimizer': 'RMSprop', 'lr': 0.001776927407239692}. Best is trial 21 with value: 0.8296875.\n",
            "[I 2024-03-26 07:06:20,668] Trial 53 finished with value: 0.8234375 and parameters: {'n_layers': 1, 'n_units_l0': 123, 'dropout_l0': 0.4920951802746698, 'optimizer': 'RMSprop', 'lr': 0.0018827475722422461}. Best is trial 21 with value: 0.8296875.\n",
            "[I 2024-03-26 07:06:28,434] Trial 54 finished with value: 0.8328125 and parameters: {'n_layers': 1, 'n_units_l0': 125, 'dropout_l0': 0.4955068739350471, 'optimizer': 'RMSprop', 'lr': 0.0017037698594591557}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:06:29,237] Trial 55 pruned. \n",
            "[I 2024-03-26 07:06:37,019] Trial 56 finished with value: 0.815625 and parameters: {'n_layers': 1, 'n_units_l0': 123, 'dropout_l0': 0.4998870686890967, 'optimizer': 'RMSprop', 'lr': 0.0029924430696031887}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:06:38,558] Trial 57 pruned. \n",
            "[I 2024-03-26 07:06:39,398] Trial 58 pruned. \n",
            "[I 2024-03-26 07:06:40,252] Trial 59 pruned. \n",
            "[I 2024-03-26 07:06:41,109] Trial 60 pruned. \n",
            "[I 2024-03-26 07:06:48,914] Trial 61 finished with value: 0.80859375 and parameters: {'n_layers': 1, 'n_units_l0': 123, 'dropout_l0': 0.4984533766935317, 'optimizer': 'RMSprop', 'lr': 0.003120381937860992}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:06:55,910] Trial 62 finished with value: 0.82578125 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'dropout_l0': 0.4762028241184008, 'optimizer': 'RMSprop', 'lr': 0.0022212837215463}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:06:56,683] Trial 63 pruned. \n",
            "[I 2024-03-26 07:06:59,841] Trial 64 pruned. \n",
            "[I 2024-03-26 07:07:01,088] Trial 65 pruned. \n",
            "[I 2024-03-26 07:07:08,202] Trial 66 finished with value: 0.8234375 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.47739287589799906, 'optimizer': 'RMSprop', 'lr': 0.002159107472064147}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:07:11,151] Trial 67 pruned. \n",
            "[I 2024-03-26 07:07:12,263] Trial 68 pruned. \n",
            "[I 2024-03-26 07:07:19,594] Trial 69 finished with value: 0.8171875 and parameters: {'n_layers': 1, 'n_units_l0': 111, 'dropout_l0': 0.46419717514968095, 'optimizer': 'RMSprop', 'lr': 0.0011174706797459667}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:07:27,325] Trial 70 finished with value: 0.8234375 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.49021582492462695, 'optimizer': 'RMSprop', 'lr': 0.0017349924693428318}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:07:28,156] Trial 71 pruned. \n",
            "[I 2024-03-26 07:07:35,098] Trial 72 finished with value: 0.8125 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.47979148429758633, 'optimizer': 'RMSprop', 'lr': 0.0019001634846999072}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:07:42,754] Trial 73 finished with value: 0.80546875 and parameters: {'n_layers': 1, 'n_units_l0': 99, 'dropout_l0': 0.4461000918854355, 'optimizer': 'RMSprop', 'lr': 0.0016221618566102907}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:07:43,562] Trial 74 pruned. \n",
            "[I 2024-03-26 07:07:44,373] Trial 75 pruned. \n",
            "[I 2024-03-26 07:07:45,132] Trial 76 pruned. \n",
            "[I 2024-03-26 07:07:45,950] Trial 77 pruned. \n",
            "[I 2024-03-26 07:07:53,762] Trial 78 finished with value: 0.78984375 and parameters: {'n_layers': 1, 'n_units_l0': 126, 'dropout_l0': 0.35386133597880626, 'optimizer': 'RMSprop', 'lr': 0.002050773670908354}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:07:56,620] Trial 79 pruned. \n",
            "[I 2024-03-26 07:07:57,444] Trial 80 pruned. \n",
            "[I 2024-03-26 07:07:58,268] Trial 81 pruned. \n",
            "[I 2024-03-26 07:07:59,087] Trial 82 pruned. \n",
            "[I 2024-03-26 07:08:06,959] Trial 83 finished with value: 0.81328125 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.4480196117323, 'optimizer': 'RMSprop', 'lr': 0.006215782264880766}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:08:07,788] Trial 84 pruned. \n",
            "[I 2024-03-26 07:08:15,862] Trial 85 finished with value: 0.82265625 and parameters: {'n_layers': 1, 'n_units_l0': 118, 'dropout_l0': 0.48513381364646474, 'optimizer': 'Adam', 'lr': 0.0033858893311042846}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:08:23,030] Trial 86 finished with value: 0.8125 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'dropout_l0': 0.4940083641619151, 'optimizer': 'Adam', 'lr': 0.0035437014568230315}. Best is trial 54 with value: 0.8328125.\n",
            "[I 2024-03-26 07:08:31,095] Trial 87 finished with value: 0.83671875 and parameters: {'n_layers': 1, 'n_units_l0': 107, 'dropout_l0': 0.48414943737271854, 'optimizer': 'Adam', 'lr': 0.008020519371984298}. Best is trial 87 with value: 0.83671875.\n",
            "[I 2024-03-26 07:08:39,226] Trial 88 finished with value: 0.84609375 and parameters: {'n_layers': 1, 'n_units_l0': 101, 'dropout_l0': 0.31971211041284947, 'optimizer': 'Adam', 'lr': 0.008204182555755073}. Best is trial 88 with value: 0.84609375.\n",
            "[I 2024-03-26 07:08:40,101] Trial 89 pruned. \n",
            "[I 2024-03-26 07:08:47,521] Trial 90 finished with value: 0.81796875 and parameters: {'n_layers': 1, 'n_units_l0': 121, 'dropout_l0': 0.2910466412222129, 'optimizer': 'Adam', 'lr': 0.016024392348051367}. Best is trial 88 with value: 0.84609375.\n",
            "[I 2024-03-26 07:08:55,665] Trial 91 finished with value: 0.81015625 and parameters: {'n_layers': 1, 'n_units_l0': 95, 'dropout_l0': 0.3269655701634134, 'optimizer': 'Adam', 'lr': 0.008070576468333215}. Best is trial 88 with value: 0.84609375.\n",
            "[I 2024-03-26 07:09:03,749] Trial 92 finished with value: 0.8453125 and parameters: {'n_layers': 1, 'n_units_l0': 101, 'dropout_l0': 0.295940381247316, 'optimizer': 'Adam', 'lr': 0.010928482813646098}. Best is trial 88 with value: 0.84609375.\n",
            "[I 2024-03-26 07:09:11,308] Trial 93 finished with value: 0.82109375 and parameters: {'n_layers': 1, 'n_units_l0': 103, 'dropout_l0': 0.27493230696540427, 'optimizer': 'Adam', 'lr': 0.009826361810617038}. Best is trial 88 with value: 0.84609375.\n",
            "[I 2024-03-26 07:09:12,145] Trial 94 pruned. \n",
            "[I 2024-03-26 07:09:20,012] Trial 95 finished with value: 0.809375 and parameters: {'n_layers': 1, 'n_units_l0': 106, 'dropout_l0': 0.29844090856624444, 'optimizer': 'Adam', 'lr': 0.005518826080456091}. Best is trial 88 with value: 0.84609375.\n",
            "[I 2024-03-26 07:09:22,898] Trial 96 pruned. \n",
            "[I 2024-03-26 07:09:30,673] Trial 97 finished with value: 0.8078125 and parameters: {'n_layers': 1, 'n_units_l0': 84, 'dropout_l0': 0.28263011806306215, 'optimizer': 'Adam', 'lr': 0.020492251604227442}. Best is trial 88 with value: 0.84609375.\n",
            "[I 2024-03-26 07:09:38,232] Trial 98 finished with value: 0.821875 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_l0': 0.21968349728779688, 'optimizer': 'Adam', 'lr': 0.00778502469675393}. Best is trial 88 with value: 0.84609375.\n",
            "[I 2024-03-26 07:09:39,275] Trial 99 pruned. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])"
      ],
      "metadata": {
        "id": "pQaBgfvckWmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC2SJrpekfTI",
        "outputId": "5ea96755-e838-4a00-9c57-be35c220eb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  100\n",
            "  Number of pruned trials:  54\n",
            "  Number of complete trials:  46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ihx7dWRkj36",
        "outputId": "8ceffe99-e394-4e83-e8a5-873dde87527a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "  Value:  0.84609375\n",
            "  Params: \n",
            "    n_layers: 1\n",
            "    n_units_l0: 101\n",
            "    dropout_l0: 0.31971211041284947\n",
            "    optimizer: Adam\n",
            "    lr: 0.008204182555755073\n"
          ]
        }
      ]
    }
  ]
}